; wget — текстовая программа для скачивания файлов.
; Если возможностей wget не хватает, то можно использовать curl.

## Примеры
; Просто скачать файл wget-ом:

wget ftp://vasya.pupkin.com/film.avi

; Для продолжения оборвавшейся закачки пишем:
wget -c ftp://vasya.pupkin.com/film.avi
; или
wget --continue ftp://vasya.pupkin.com/film.avi
; Как и в других программах, ключи имеют короткую и длинную формы, и вместо -с можно написать -continue.
;  Длинные ключи проще запомнить, но дольше писать. Можно легко смешивать различные формы написания.
; Чтобы выкачать файлы из списка, содержащего прямые ссылки:

wget -c -t 0 http://www.x11amp.bz.nu/files/x11amp-0.9-beta1.1.tar.gz
; Для того, чтобы wget повторял попытки взять файл до тех пор, пока не скачает его целиком, надо указывать ключи "-c" и "-t 0". 
; Первый означает "продолжать качать с того места, где соединение оборвалось" (continue), 
; а второй позволяет указать число попыток, 0 -- бесконечно.

# Фоновый режим
wget -b http://www.mit.edu/afs/sipb/user/xiphmont/cdparanoia/download/cdparanoia-III-alpha9.5.src.tgz
; При указании ключа "-b" (background) программа сразу переходит в фоновый режим, так что пользователь
; может заниматься другими делами или даже выйти из системы -- wget будет продолжать свою работу.
; При сообщения, которые выдавались бы на экран, будут идти в файл wget.log (а если он уже есть, то в wget.log.1, wget.log.2 и т.д.).
tail -f wget-log
; Для просмотра log-файла по мере скачивания удобно пользоваться командой "tail -f"

; Wget понимает как "официальное" указание адреса, так и сокращенное. Поэтому команды
export http_proxy=http://proxy.nsc.ru:8080/
; и
export http_proxy=proxy.nsc.ru:8080
; эквивалентны.


wget -i pupkinlist.txt
; или
wget --input-file=pupkinlist.txt
; Здесь указывается только файл, в котором содержатся ссылки. Файл может так же быть HTML-страницей, в которой есть ссылки.
;  Они будут выкачаны указанной выше командой.

; Использование а-ля «Teleport Pro for Linux».
; При скачивании веб-сайтов возможностей больше, и поэтому требуется больше ключей. 
; Опять-таки, запоминать их все не обязательно, можно сделать скрипт (а лучше несколько - под разные случаи) и вызывать их.

; Так вот, если имеется веб-сайт, и хотелось бы иметь его локальную копию на компьютере, чтобы, отключившись от сети, можно было не торопясь его почитать.

; Зеркалирование сайтов на локальную машину:
wget -m http://www.vasyapupkin.com/
# -m эквивалентно -r -N -l inf -nr, эти опции описаны ниже.
; При этом ссылки останутся абсолютными - то есть, будут указывать на Интернет-адреса, и удобно просматривать на локальной машине будет затруднительно.

; Копирование сайта для локального просмотра (с заменой интернет-ссылок на локальные адреса скачанных страниц):
wget -r -l0 -k http://www.vasyapupkin.com/
; При этом будет включена рекурсивная выгрузка (ключ -r, –recursive),

; Опции
; В wget имеется большое количество полезных опций - побольше, чем у Teleport'а флажков. Будучи завёрнутым в скрипт, например, teleport и положенным на видное место (указанное в PATH), имеем удобство применения и богатство настроек.

-np, –no-parent — не подниматься выше начального адреса при рекурсивной загрузке.

-r, –recursive — включить рекурсивный просмотр каталогов и подкаталогов на удалённом сервере.

-l <depth>, –level=<depth> — определить максимальную глубину рекурсии равной depth при просмотре каталогов на удалённом сервере. По умолчанию depth=5.

-np, –no-parent — не переходить в родительский каталог во время поиска файлов. Это очень полезное свойство, поскольку оно гарантирует, что будут копироваться только те файлы, которые расположены ниже определённой иерархии.

-A <acclist>, –accept <acclist>, -R <rejlist>, –reject <rejlist> — список имен файлов, разделенных запятыми, которые следует (accept) или не следует (reject) загружать. Разрешается задание имен файлов по маске.

-k, –convert-links — превратить абсолютные ссылки в HTML документе в относительные ссылки. Преобразованию подвергнутся только те ссылки, которые указывают на реально загруженные страницы; остальные не будут преобразовываться. Заметим, что лишь в конце работы wget сможет узнать какие страницы были реально загружены. Следовательно, лишь в конце работы wget будет выполняться окончательное преобразование.

–http-user=<user>, –http-passwd=<password> — указать имя пользователя и пароль на HTTP-сервере.

-H, –span-hosts — разрешает посещать любые сервера, на которые есть ссылка.

-p, –page-requisites — загружать все файлы, которые нужны для отображения страниц HTML. Например: рисунки, звук, каскадные стили (CSS). По умолчанию такие файлы не загружаются. Параметры -r и -l, указанные вместе могут помочь, но т.к. wget не различает внешние и внутренние документы, то нет гарантии, что загрузится все требуемое.